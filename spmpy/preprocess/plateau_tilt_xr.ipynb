{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e3bde94",
   "metadata": {},
   "source": [
    "\n",
    "# Plateau-based Tilt Removal for STM (sxm images)\n",
    "\n",
    "This notebook provides a **physically motivated tilt-correction method** for\n",
    "2D STM images (`.sxm`), based on **automatic plateau (terrace) detection**.\n",
    "\n",
    "Unlike generic plane fitting, this approach:\n",
    "- Uses **terraces as physical references**\n",
    "- Removes only the **average global tilt**\n",
    "- **Preserves step heights and absolute offsets**\n",
    "\n",
    "---\n",
    "\n",
    "## Conceptual Overview\n",
    "\n",
    "1. **Noise suppression**  \n",
    "   A Gaussian filter is applied before gradient computation.\n",
    "\n",
    "2. **Step edge detection**  \n",
    "   The gradient magnitude \\(|âˆ‡z|\\) is used to identify step edges.\n",
    "\n",
    "3. **Plateau (terrace) identification**  \n",
    "   Low-gradient regions are treated as plateaus.\n",
    "   Connected-component labeling separates individual terraces.\n",
    "\n",
    "4. **Local plane fitting on plateaus**  \n",
    "   For each plateau:\n",
    "   \\[\n",
    "   z(x,y) â‰ˆ a_i x + b_i y + c_i\n",
    "   \\]\n",
    "   Only the slope terms \\((a_i, b_i)\\) are retained.\n",
    "\n",
    "5. **Area-weighted averaging**  \n",
    "   The global tilt is estimated as:\n",
    "   \\[\n",
    "   a_{avg} = \\frac{\\sum A_i a_i}{\\sum A_i}, \\quad\n",
    "   b_{avg} = \\frac{\\sum A_i b_i}{\\sum A_i}\n",
    "   \\]\n",
    "\n",
    "6. **Tilt removal**  \n",
    "   Only the averaged tilt plane is removed:\n",
    "   \\[\n",
    "   z_{corr}(x,y) = z(x,y) - (a_{avg} x + b_{avg} y)\n",
    "   \\]\n",
    "   The height offset is preserved.\n",
    "\n",
    "---\n",
    "\n",
    "## Design Principles\n",
    "\n",
    "- **2D STM images only** (sxm-style, no grid / bias dimension)\n",
    "- **Mask support**\n",
    "  - `mask == True`  â†’ included in plateau detection and fitting\n",
    "  - `mask == False` â†’ excluded\n",
    "- **API consistency** with `plane_fit_xr`\n",
    "- **Safe defaults**\n",
    "  - `ch='all'`\n",
    "  - `mask=None`\n",
    "  - `overwrite=False`\n",
    "\n",
    "---\n",
    "\n",
    "## Typical Usage\n",
    "\n",
    "```python\n",
    "ds_corr = plateau_tilt_xr(\n",
    "    ds_sxm,\n",
    "    ch=\"Z_fwd\",\n",
    "    grad_sigma=1.0,\n",
    "    min_plateau_area=300,\n",
    ")\n",
    "```\n",
    "\n",
    "### Using a reference mask\n",
    "```python\n",
    "ds_corr = plateau_tilt_xr(\n",
    "    ds_sxm,\n",
    "    ch=\"Z_fwd\",\n",
    "    mask=terrace_mask,\n",
    ")\n",
    "```\n",
    "\n",
    "### Overwriting the original channel\n",
    "```python\n",
    "ds_corr = plateau_tilt_xr(\n",
    "    ds_sxm,\n",
    "    ch=\"Z_fwd\",\n",
    "    overwrite=True,\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0a43d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy.ndimage import gaussian_filter, label\n",
    "\n",
    "\n",
    "def plateau_tilt_xr(\n",
    "    ds: xr.Dataset,\n",
    "    ch: str = \"all\",\n",
    "    grad_sigma: float = 1.0,\n",
    "    grad_threshold: float | None = None,\n",
    "    min_plateau_area: int = 200,\n",
    "    mask: np.ndarray | None = None,\n",
    "    overwrite: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plateau (terrace) based tilt removal for 2D STM images (sxm).\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(ds, xr.Dataset):\n",
    "        raise TypeError(\"Input must be an xarray.Dataset\")\n",
    "\n",
    "    if ch == \"all\":\n",
    "        ch_list = list(ds.data_vars)\n",
    "    else:\n",
    "        if ch not in ds.data_vars:\n",
    "            raise ValueError(f\"Channel '{ch}' not found\")\n",
    "        ch_list = [ch]\n",
    "\n",
    "    out = ds.copy()\n",
    "\n",
    "    for var in ch_list:\n",
    "        da = ds[var]\n",
    "        if da.ndim != 2:\n",
    "            continue\n",
    "\n",
    "        y_dim, x_dim = da.dims\n",
    "        x = da[x_dim].values\n",
    "        y = da[y_dim].values\n",
    "        Z = da.values.astype(float)\n",
    "\n",
    "        if mask is not None and mask.shape != Z.shape:\n",
    "            raise ValueError(\"mask must have the same shape as the image\")\n",
    "\n",
    "        Z_smooth = gaussian_filter(Z, sigma=float(grad_sigma))\n",
    "        dZdy, dZdx = np.gradient(Z_smooth, y, x)\n",
    "        grad = np.sqrt(dZdx**2 + dZdy**2)\n",
    "\n",
    "        if grad_threshold is None:\n",
    "            grad_thr = np.nanmedian(grad) + 2.0 * np.nanstd(grad)\n",
    "        else:\n",
    "            grad_thr = float(grad_threshold)\n",
    "\n",
    "        step_mask = grad > grad_thr\n",
    "        plateau_mask = ~step_mask\n",
    "\n",
    "        if mask is not None:\n",
    "            plateau_mask &= mask\n",
    "\n",
    "        labels, n_labels = label(plateau_mask)\n",
    "        Xg, Yg = np.meshgrid(x, y)\n",
    "\n",
    "        slopes = []\n",
    "        areas = []\n",
    "\n",
    "        for lab in range(1, n_labels + 1):\n",
    "            region = labels == lab\n",
    "            area = int(np.count_nonzero(region))\n",
    "            if area < min_plateau_area:\n",
    "                continue\n",
    "\n",
    "            xr_p = Xg[region]\n",
    "            yr_p = Yg[region]\n",
    "            zr_p = Z[region]\n",
    "\n",
    "            A = np.column_stack([xr_p, yr_p, np.ones_like(xr_p)])\n",
    "            coeff, _, _, _ = np.linalg.lstsq(A, zr_p, rcond=None)\n",
    "            a_i, b_i, _ = coeff\n",
    "\n",
    "            slopes.append((float(a_i), float(b_i)))\n",
    "            areas.append(area)\n",
    "\n",
    "        if not slopes:\n",
    "            raise RuntimeError(\"No valid plateaus detected.\")\n",
    "\n",
    "        slopes = np.asarray(slopes)\n",
    "        areas = np.asarray(areas)\n",
    "\n",
    "        a_avg = float(np.average(slopes[:, 0], weights=areas))\n",
    "        b_avg = float(np.average(slopes[:, 1], weights=areas))\n",
    "\n",
    "        tilt_plane = a_avg * Xg + b_avg * Yg\n",
    "        Z_corr = Z - tilt_plane\n",
    "\n",
    "        out_da = xr.DataArray(Z_corr, coords=da.coords, dims=da.dims, attrs=da.attrs)\n",
    "\n",
    "        if overwrite:\n",
    "            out[var] = out_da\n",
    "        else:\n",
    "            out[f\"{var}_plateautilt\"] = out_da\n",
    "\n",
    "        out.attrs[f\"{var}_plateau_tilt\"] = {\n",
    "            \"a_avg\": a_avg,\n",
    "            \"b_avg\": b_avg,\n",
    "            \"n_plateaus\": int(len(areas)),\n",
    "            \"grad_sigma\": float(grad_sigma),\n",
    "            \"grad_threshold\": float(grad_thr),\n",
    "            \"min_plateau_area\": int(min_plateau_area),\n",
    "        }\n",
    "\n",
    "    return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5509aefd",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ§­ Plateau Existence Decision Logic (Pre-Fit Validation)\n",
    "\n",
    "### Motivation\n",
    "Plateau fitting should **only** be performed when a physically meaningful\n",
    "flat (plane-like) region exists in the image. Blindly applying plateau fitting\n",
    "can lead to unstable parameters and misleading results.\n",
    "\n",
    "Therefore, a **pre-fit validation step** is introduced.\n",
    "\n",
    "---\n",
    "\n",
    "### Plateau / Plane Detection Strategy\n",
    "\n",
    "1. **Plane-like region detection**\n",
    "   - A plane (low-gradient region) is identified based on a local gradient\n",
    "     or residual criterion (implementation-dependent).\n",
    "   - Only pixels satisfying the plane criterion are considered\n",
    "     *plateau candidates*.\n",
    "\n",
    "2. **Area fraction requirement**\n",
    "   - Let:\n",
    "     - `N_plateau` = number of pixels classified as plateau\n",
    "     - `N_total` = total number of pixels in the image\n",
    "   - Plateau fitting is allowed **only if**:\n",
    "     ```\n",
    "     (N_plateau / N_total) â‰¥ 0.10\n",
    "     ```\n",
    "     i.e. at least **10% of the total image area**.\n",
    "\n",
    "---\n",
    "\n",
    "### Control Flow\n",
    "\n",
    "1. Existing preprocessing (tilt removal, background correction, etc.) runs first.\n",
    "2. Plateau candidate region is evaluated.\n",
    "3. A message is printed:\n",
    "   - If no valid plane is found:\n",
    "     - `\"No plateau region detected â€” plateau fitting skipped.\"`\n",
    "   - If a plane is found:\n",
    "     - `\"Plateau region detected: XX.X% of total area.\"`\n",
    "4. Plateau fitting is executed **only if** the area threshold is satisfied.\n",
    "\n",
    "---\n",
    "\n",
    "### Design Principles\n",
    "- Existing plateau fitting logic is **unchanged**\n",
    "- Decision logic is **additive and explicit**\n",
    "- No side effects on downstream analysis\n",
    "- Messages are always printed before fitting\n",
    "\n",
    "This ensures transparent, reproducible, and physically meaningful plateau analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6e7c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "def detect_plateau_region(\n",
    "    data: np.ndarray,\n",
    "    gradient_threshold: float,\n",
    "):\n",
    "    \"\"\"\n",
    "    Detect plane-like (plateau) regions based on gradient magnitude.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        2D input image.\n",
    "    gradient_threshold : float\n",
    "        Threshold on gradient magnitude below which pixels\n",
    "        are considered part of a plane.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    plateau_mask : np.ndarray of bool\n",
    "        Boolean mask indicating plateau candidate pixels.\n",
    "    \"\"\"\n",
    "    gy, gx = np.gradient(data)\n",
    "    grad_mag = np.sqrt(gx**2 + gy**2)\n",
    "    plateau_mask = grad_mag < gradient_threshold\n",
    "    return plateau_mask\n",
    "\n",
    "\n",
    "def plateau_area_fraction(plateau_mask: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute the fractional area occupied by the plateau region.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    plateau_mask : np.ndarray of bool\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fraction : float\n",
    "        Plateau area fraction relative to the full image.\n",
    "    \"\"\"\n",
    "    return np.count_nonzero(plateau_mask) / plateau_mask.size\n",
    "\n",
    "\n",
    "def should_run_plateau_fit(\n",
    "    data: np.ndarray,\n",
    "    gradient_threshold: float,\n",
    "    min_fraction: float = 0.10,\n",
    "):\n",
    "    \"\"\"\n",
    "    Decide whether plateau fitting should be performed.\n",
    "\n",
    "    The decision is based on whether a plane-like region\n",
    "    exists and occupies at least a minimum fraction\n",
    "    of the total image area.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        2D image after preprocessing.\n",
    "    gradient_threshold : float\n",
    "        Gradient magnitude threshold for plane detection.\n",
    "    min_fraction : float, optional\n",
    "        Minimum required plateau area fraction (default: 0.10).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    run_fit : bool\n",
    "        Whether plateau fitting should be executed.\n",
    "    plateau_fraction : float\n",
    "        Detected plateau area fraction.\n",
    "    plateau_mask : np.ndarray of bool\n",
    "        Mask of detected plateau region.\n",
    "    \"\"\"\n",
    "    plateau_mask = detect_plateau_region(data, gradient_threshold)\n",
    "    fraction = plateau_area_fraction(plateau_mask)\n",
    "\n",
    "    if fraction == 0.0:\n",
    "        print(\"No plateau region detected â€” plateau fitting skipped.\")\n",
    "        return False, fraction, plateau_mask\n",
    "\n",
    "    print(\n",
    "        f\"Plateau region detected: {fraction * 100:.1f}% of total area.\"\n",
    "    )\n",
    "\n",
    "    if fraction < min_fraction:\n",
    "        print(\n",
    "            f\"Plateau area below threshold ({min_fraction * 100:.0f}%) â€” fitting skipped.\"\n",
    "        )\n",
    "        return False, fraction, plateau_mask\n",
    "\n",
    "    return True, fraction, plateau_mask\n",
    "\n",
    "\n",
    "def run_plateau_fit_if_valid(\n",
    "    data: np.ndarray,\n",
    "    gradient_threshold: float,\n",
    "    min_fraction: float,\n",
    "    plateau_fit_func,\n",
    "    *args,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Wrapper that conditionally executes plateau fitting.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        2D image after preprocessing.\n",
    "    gradient_threshold : float\n",
    "        Threshold for plane detection.\n",
    "    min_fraction : float\n",
    "        Minimum required plateau area fraction.\n",
    "    plateau_fit_func : callable\n",
    "        Existing plateau fitting function.\n",
    "    *args, **kwargs :\n",
    "        Passed directly to `plateau_fit_func`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result or None\n",
    "        Output of `plateau_fit_func` if executed,\n",
    "        otherwise None.\n",
    "    \"\"\"\n",
    "    run_fit, frac, mask = should_run_plateau_fit(\n",
    "        data,\n",
    "        gradient_threshold,\n",
    "        min_fraction,\n",
    "    )\n",
    "\n",
    "    if not run_fit:\n",
    "        return None\n",
    "\n",
    "    return plateau_fit_func(data, mask=mask, *args, **kwargs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2d3abf",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ§¯ Fix for `TypeError: Invalid value for attr ... {dict}` when saving to NetCDF\n",
    "\n",
    "### Why this happens\n",
    "`xarray.Dataset.to_netcdf()` validates that **attribute values** are NetCDF-serializable.\n",
    "A Python `dict` stored in `ds.attrs[...]` (e.g. `ds.attrs[\"Z_fwd_plateau_tilt\"] = {...}`)\n",
    "is **not** directly serializable, so `to_netcdf()` raises:\n",
    "\n",
    "- `TypeError: Invalid value for attr '...': {...dict...}`\n",
    "\n",
    "### Policy (no side effects)\n",
    "- **Do not modify** existing attrs in the in-memory Dataset used for analysis\n",
    "- Make a **shallow copy only for writing**, and convert *only the new plateau attrs*\n",
    "  (or any explicitly-scoped attrs) to a NetCDF-safe representation.\n",
    "\n",
    "### Recommended representation\n",
    "- Convert dict-like plateau metadata to a **JSON string** at write time.\n",
    "  - Human-readable\n",
    "  - Reversible (can be loaded back with `json.loads`)\n",
    "  - NetCDF-safe (`str`)\n",
    "\n",
    "### Two ways to use\n",
    "1. **Explicit key list**: if you know which attrs were added after plateau.\n",
    "2. **Snapshot-based auto detection**: capture attrs before plateau, then after plateau;\n",
    "   only newly-added or modified keys are sanitized at save time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa59c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, Iterable, Optional, Tuple\n",
    "\n",
    "def _attr_value_to_netcdf_safe(value: Any) -> Any:\n",
    "    \"\"\"\n",
    "    Convert a single attribute value to a NetCDF-safe type.\n",
    "\n",
    "    Rules\n",
    "    -----\n",
    "    - Keep: str, numbers, numpy scalars, bytes, lists/tuples of basic scalars\n",
    "    - Convert: dict -> JSON string\n",
    "    - Keep: numpy arrays (NetCDF supports ndarray attrs)\n",
    "    - Fallback: any other object -> string\n",
    "    \"\"\"\n",
    "    # dict -> JSON string (preferred for structured metadata)\n",
    "    if isinstance(value, dict):\n",
    "        return json.dumps(value, ensure_ascii=False, sort_keys=True)\n",
    "\n",
    "    # numpy arrays are allowed in attrs for NetCDF\n",
    "    if isinstance(value, np.ndarray):\n",
    "        return value\n",
    "\n",
    "    # scalar numbers / numpy scalars / strings\n",
    "    if np.isscalar(value):\n",
    "        if isinstance(value, str):\n",
    "            return value\n",
    "        try:\n",
    "            return value.item()\n",
    "        except Exception:\n",
    "            return value\n",
    "\n",
    "    # list/tuple: ensure elements are simple\n",
    "    if isinstance(value, (list, tuple)):\n",
    "        safe_list = []\n",
    "        for v in value:\n",
    "            if isinstance(v, dict):\n",
    "                safe_list.append(json.dumps(v, ensure_ascii=False, sort_keys=True))\n",
    "            elif np.isscalar(v) and not isinstance(v, str):\n",
    "                try:\n",
    "                    safe_list.append(v.item())\n",
    "                except Exception:\n",
    "                    safe_list.append(v)\n",
    "            else:\n",
    "                safe_list.append(str(v))\n",
    "        return type(value)(safe_list)\n",
    "\n",
    "    # bytes is valid for some engines\n",
    "    if isinstance(value, (bytes, bytearray)):\n",
    "        return bytes(value)\n",
    "\n",
    "    # fallback: stringify\n",
    "    return str(value)\n",
    "\n",
    "\n",
    "def to_netcdf_scoped_attrs(\n",
    "    ds: xr.Dataset,\n",
    "    path: str,\n",
    "    scoped_attr_keys: Iterable[str],\n",
    "    encoding: Optional[Dict[str, Dict[str, Any]]] = None,\n",
    "    **to_netcdf_kwargs,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Write a Dataset to NetCDF while sanitizing ONLY the specified attrs.\n",
    "\n",
    "    Important\n",
    "    ---------\n",
    "    - The input Dataset `ds` is NOT modified.\n",
    "    - A shallow copy is created for writing.\n",
    "    \"\"\"\n",
    "    attrs_out = dict(ds.attrs)\n",
    "    for k in scoped_attr_keys:\n",
    "        if k in attrs_out:\n",
    "            attrs_out[k] = _attr_value_to_netcdf_safe(attrs_out[k])\n",
    "\n",
    "    ds_out = ds.copy(deep=False)\n",
    "    ds_out.attrs = attrs_out\n",
    "\n",
    "    ds_out.to_netcdf(path, encoding=encoding or {}, **to_netcdf_kwargs)\n",
    "    print(f\"NetCDF written (scoped attrs only) to: {path}\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AttrSnapshot:\n",
    "    \"\"\"\n",
    "    Snapshot Dataset attrs and compute which keys are new/changed.\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    snap = AttrSnapshot.from_dataset(ds_before_plateau)\n",
    "    # ... plateau processing that adds/modifies ds.attrs ...\n",
    "    keys = snap.diff(ds_after_plateau)\n",
    "    to_netcdf_scoped_attrs(ds_after_plateau, \"out.nc\", keys)\n",
    "    \"\"\"\n",
    "    baseline: Dict[str, Any]\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataset(cls, ds: xr.Dataset) -> \"AttrSnapshot\":\n",
    "        return cls(baseline=dict(ds.attrs))\n",
    "\n",
    "    def diff(self, ds: xr.Dataset) -> Tuple[str, ...]:\n",
    "        \"\"\"\n",
    "        Return keys that are newly added or changed vs baseline.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        - Best-effort equality check that tolerates dict/list/ndarray.\n",
    "        \"\"\"\n",
    "        current = dict(ds.attrs)\n",
    "        keys = set(current.keys()) | set(self.baseline.keys())\n",
    "        changed = []\n",
    "        for k in keys:\n",
    "            if k not in self.baseline:\n",
    "                changed.append(k)\n",
    "                continue\n",
    "            if k not in current:\n",
    "                continue\n",
    "\n",
    "            a = self.baseline[k]\n",
    "            b = current[k]\n",
    "\n",
    "            try:\n",
    "                eq = (a == b)\n",
    "                if isinstance(eq, np.ndarray):\n",
    "                    eq = bool(np.all(eq))\n",
    "            except Exception:\n",
    "                eq = (str(a) == str(b))\n",
    "\n",
    "            if not eq:\n",
    "                changed.append(k)\n",
    "\n",
    "        return tuple(sorted(changed))\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
