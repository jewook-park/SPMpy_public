{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "023b506e",
   "metadata": {},
   "source": [
    "# interpolate2D_xr â€” Square-Pixel Interpolation for 2D STM Images\n",
    "\n",
    "This notebook documents the function **`interpolate2D_xr`**,  \n",
    "a geometry-correction utility for **2D STM (sxm) images** stored in an\n",
    "`xarray.Dataset`.\n",
    "\n",
    "The purpose of this function is to **enforce square pixels**  \n",
    "(i.e. identical physical pixel spacing along X and Y: `dx = dy`)\n",
    "while preserving the true physical scan dimensions.\n",
    "\n",
    "---\n",
    "\n",
    "## Purpose\n",
    "\n",
    "STM images often have different physical pixel spacings along the scan axes:\n",
    "\n",
    "- different scan ranges in X and Y\n",
    "- different pixel counts along X and Y\n",
    "\n",
    "This results in **anisotropic pixels** (`dx â‰  dy`), which can distort:\n",
    "\n",
    "- plane fitting and background removal\n",
    "- FFT and reciprocal-space analysis\n",
    "- gradient-based operations\n",
    "- quantitative line profiles\n",
    "\n",
    "`interpolate2D_xr` explicitly corrects this geometry by interpolating the image\n",
    "onto a **square-pixel grid** based on the physical scan dimensions.\n",
    "\n",
    "---\n",
    "\n",
    "## Physical Definition of Square Pixels\n",
    "\n",
    "Given the coordinate arrays:\n",
    "\n",
    "- `X = [x_min, â€¦, x_max]`\n",
    "- `Y = [y_min, â€¦, y_max]`\n",
    "\n",
    "define the physical extents and original spacings:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fb6e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import json\n",
    "\n",
    "\n",
    "def _as_sorted_xy(ds: xr.Dataset, x_name: str = \"X\", y_name: str = \"Y\") -> xr.Dataset:\n",
    "    \"\"\"Return a copy sorted by X then Y to guarantee monotonic coordinates for interpolation.\"\"\"\n",
    "    ds2 = ds.copy()\n",
    "    if x_name in ds2.coords:\n",
    "        ds2 = ds2.sortby(x_name)\n",
    "    if y_name in ds2.coords:\n",
    "        ds2 = ds2.sortby(y_name)\n",
    "    return ds2\n",
    "\n",
    "\n",
    "def interpolate2D_xr(\n",
    "    ds: xr.Dataset,\n",
    "    ch: str = \"all\",\n",
    "    overwrite: bool = True,\n",
    "    method: str = \"linear\",\n",
    "    x_name: str = \"X\",\n",
    "    y_name: str = \"Y\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Interpolate 2D STM images to enforce square pixels (dx == dy) **without introducing NaNs**.\n",
    "\n",
    "    Key point (important)\n",
    "    ---------------------\n",
    "    The output Dataset MUST use the interpolated coordinates. If you interpolate variables\n",
    "    and then assign them into a copy of the original Dataset (with old coords),\n",
    "    xarray will align by coordinate labels and reindex, creating NaNs.\n",
    "\n",
    "    This function avoids that by using the interpolated Dataset (`ds_interp`) as the output container.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : xarray.Dataset\n",
    "        Input dataset. Must contain coordinates `x_name` and `y_name` (defaults: 'X', 'Y').\n",
    "\n",
    "    ch : str, default 'all'\n",
    "        Channel selection.\n",
    "        - 'all' : apply to all 2D variables with dims (Y, X) (in any order)\n",
    "        - otherwise : apply to the named variable only\n",
    "\n",
    "    overwrite : bool, default True\n",
    "        - True  : output keeps original variable names on the new square-pixel grid.\n",
    "        - False : output contains BOTH:\n",
    "            * original variables on dims (Y0, X0)\n",
    "            * interpolated variables on dims (Y, X) named '{var}_interp'\n",
    "\n",
    "        This is implemented by renaming the original dataset's dims to (Y0, X0) before merging,\n",
    "        so there is no coordinate collision.\n",
    "\n",
    "    method : str, default 'linear'\n",
    "        Interpolation method used by xarray (`Dataset.interp`). Common: 'linear', 'nearest'.\n",
    "\n",
    "    x_name, y_name : str\n",
    "        Names of x and y coordinates. Defaults match SPMpy sxm convention.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xarray.Dataset\n",
    "        Interpolated dataset with dx == dy (square pixels). NetCDF-safe diagnostic metadata is stored\n",
    "        in `attrs['interpolate2D']` as a JSON string.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - 2D-only: variables must have exactly two dims corresponding to (Y, X) (order may vary).\n",
    "    - No 3D grid spectroscopy support here (bias axis etc.).\n",
    "    - Coordinates are sorted before interpolation for safety.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(ds, xr.Dataset):\n",
    "        raise TypeError(\"interpolate2D_xr expects an xarray.Dataset\")\n",
    "\n",
    "    if x_name not in ds.coords or y_name not in ds.coords:\n",
    "        raise ValueError(f\"Dataset must contain coordinates '{x_name}' and '{y_name}'\")\n",
    "\n",
    "    # Sort for monotonic coordinates (required by xarray/scipy interpolation)\n",
    "    ds_sorted = _as_sorted_xy(ds, x_name=x_name, y_name=y_name)\n",
    "\n",
    "    # Channel list\n",
    "    if ch == \"all\":\n",
    "        ch_list = list(ds_sorted.data_vars)\n",
    "    else:\n",
    "        if ch not in ds_sorted.data_vars:\n",
    "            raise ValueError(f\"Channel '{ch}' not found in Dataset\")\n",
    "        ch_list = [ch]\n",
    "\n",
    "    # Physical extents and current spacings\n",
    "    X = np.asarray(ds_sorted[x_name].values, dtype=float)\n",
    "    Y = np.asarray(ds_sorted[y_name].values, dtype=float)\n",
    "\n",
    "    x_min, x_max = float(X.min()), float(X.max())\n",
    "    y_min, y_max = float(Y.min()), float(Y.max())\n",
    "\n",
    "    Nx, Ny = len(X), len(Y)\n",
    "\n",
    "    Lx = x_max - x_min\n",
    "    Ly = y_max - y_min\n",
    "\n",
    "    dx = Lx / max(Nx - 1, 1)\n",
    "    dy = Ly / max(Ny - 1, 1)\n",
    "\n",
    "    # Target spacing: choose the smaller spacing to avoid inventing detail\n",
    "    d = min(dx, dy)\n",
    "\n",
    "    Nx_new = int(np.floor(Lx / d)) + 1\n",
    "    Ny_new = int(np.floor(Ly / d)) + 1\n",
    "\n",
    "    X_new = np.linspace(x_min, x_max, Nx_new)\n",
    "    Y_new = np.linspace(y_min, y_max, Ny_new)\n",
    "\n",
    "    # Interpolate the dataset onto the new square-pixel grid\n",
    "    ds_interp = ds_sorted.interp({x_name: X_new, y_name: Y_new}, method=method)\n",
    "\n",
    "    # Build NetCDF-safe diagnostics (JSON)\n",
    "    diag = dict(\n",
    "        x_name=str(x_name),\n",
    "        y_name=str(y_name),\n",
    "        dx_original=float(dx),\n",
    "        dy_original=float(dy),\n",
    "        dx_new=float(abs(X_new[1] - X_new[0])) if len(X_new) > 1 else float(\"nan\"),\n",
    "        dy_new=float(abs(Y_new[1] - Y_new[0])) if len(Y_new) > 1 else float(\"nan\"),\n",
    "        Nx_new=int(Nx_new),\n",
    "        Ny_new=int(Ny_new),\n",
    "        method=str(method),\n",
    "    )\n",
    "\n",
    "    # Update spacing attrs if they exist (keep compatible with SPMpy conventions)\n",
    "    out_interp = ds_interp.copy()\n",
    "    if \"X_spacing\" in out_interp.attrs:\n",
    "        out_interp.attrs[\"X_spacing\"] = float(abs(X_new[1] - X_new[0])) if len(X_new) > 1 else out_interp.attrs[\"X_spacing\"]\n",
    "    if \"Y_spacing\" in out_interp.attrs:\n",
    "        out_interp.attrs[\"Y_spacing\"] = float(abs(Y_new[1] - Y_new[0])) if len(Y_new) > 1 else out_interp.attrs[\"Y_spacing\"]\n",
    "\n",
    "    out_interp.attrs[\"interpolate2D\"] = json.dumps(diag)\n",
    "\n",
    "    # If overwrite=True, we are done. The dataset coords already match the interpolated variables.\n",
    "    if overwrite:\n",
    "        # Optionally restrict to selected channels by dropping other vars (only if user didn't request all).\n",
    "        # Here we keep all vars by default to match typical SPMpy workflow.\n",
    "        return out_interp\n",
    "\n",
    "    # overwrite=False: return dataset containing BOTH original and interpolated results.\n",
    "    # We rename original coords/dims so they do not collide with the new (X,Y).\n",
    "    ds_orig = ds_sorted.copy()\n",
    "\n",
    "    # Rename coords and dims of the original dataset\n",
    "    rename_map = {x_name: f\"{x_name}0\", y_name: f\"{y_name}0\"}\n",
    "    ds_orig = ds_orig.rename(rename_map)\n",
    "\n",
    "    # Also rename the dims for each variable that used (Y,X)\n",
    "    # (rename above already handles coordinate dimension variables in xarray)\n",
    "\n",
    "    # Keep only the requested channels in the merged output (optional)\n",
    "    # Here: include all original vars, but interpolated vars are stored with _interp suffix for clarity.\n",
    "    ds_interp_suffix = out_interp.copy()\n",
    "    ds_interp_suffix = ds_interp_suffix.rename({var: f\"{var}_interp\" for var in ch_list if var in ds_interp_suffix.data_vars})\n",
    "\n",
    "    merged = xr.merge([ds_orig, ds_interp_suffix], compat=\"no_conflicts\")\n",
    "\n",
    "    # Carry over diagnostics (JSON) at top-level attrs\n",
    "    merged.attrs = dict(ds_sorted.attrs)\n",
    "    # NetCDF-safe flattened interpolate2D diagnostics\n",
    "    for k, v in diag.items():\n",
    "        key = f\"interpolate2D_{k}\"\n",
    "        if np.isscalar(v):\n",
    "            merged.attrs[key] = float(v)\n",
    "        else:\n",
    "            merged.attrs[key] = str(v)\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d25b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional quick validation (edit the path to your local file)\n",
    "# import xarray as xr, numpy as np\n",
    "# ds = xr.open_dataset(\"ds_sxm_cu.nc\")\n",
    "# ds_iso = interpolate2D_xr(ds, overwrite=True)\n",
    "# print(\"Original sizes:\", dict(ds.sizes))\n",
    "# print(\"Interpolated sizes:\", dict(ds_iso.sizes))\n",
    "# print(\"dx_new == dy_new?\",\n",
    "#       np.isclose(ds_iso.attrs.get(\"X_spacing\", np.nan), ds_iso.attrs.get(\"Y_spacing\", np.nan)))\n",
    "# print(\"NaNs in Z_fwd:\", int(np.isnan(ds_iso[\"Z_fwd\"].values).sum()))\n",
    "# ds_iso.to_netcdf(\"ds_iso_cu.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d43a39",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ“Œ Record: interpolate2D NetCDF-safe attrs (Flattened)\n",
    "\n",
    "- interpolate2D diagnostics are now written as **flattened attrs**\n",
    "  (e.g. `interpolate2D_method`, `interpolate2D_dx_new`, ...).\n",
    "- No JSON string or save-time compatibility flags are used.\n",
    "- NetCDF compatibility is guaranteed at function execution time.\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
